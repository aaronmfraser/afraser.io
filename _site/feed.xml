<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">Aaron Fraser</title>
<subtitle type="text">Distilled thought of a Systems Engineer</subtitle>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://0.0.0.0:4000/feed.xml" />
<link rel="alternate" type="text/html" href="http://0.0.0.0:4000" />
<updated>2014-03-01T01:42:32-08:00</updated>
<id>http://0.0.0.0:4000/</id>
<author>
  <name>Aaron Fraser</name>
  <uri>http://0.0.0.0:4000/</uri>
  <email>me@afraser.io</email>
</author>


<entry>
  <title type="html"><![CDATA[Proxies And The Middle East]]></title>
  <link rel="alternate" type="text/html" href="http://0.0.0.0:4000/proxies-and-the-middle-east/" />
  <id>http://0.0.0.0:4000/proxies-and-the-middle-east</id>
  <published>2014-03-01T01:39:51-08:00</published>
  <updated>2014-03-01T01:39:51-08:00</updated>
  <author>
    <name>Aaron Fraser</name>
    <uri>http://0.0.0.0:4000</uri>
    <email>me@afraser.io</email>
  </author>
  <content type="html">

  &lt;p&gt;&lt;a href=&quot;http://0.0.0.0:4000/proxies-and-the-middle-east/&quot;&gt;Proxies And The Middle East&lt;/a&gt; was originally published by Aaron Fraser at &lt;a href=&quot;http://0.0.0.0:4000&quot;&gt;Aaron Fraser&lt;/a&gt; on March 01, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Storage For Vmware]]></title>
  <link rel="alternate" type="text/html" href="http://0.0.0.0:4000/storage-for-vmware/" />
  <id>http://0.0.0.0:4000/storage-for-vmware</id>
  <published>2014-03-01T01:39:14-08:00</published>
  <updated>2014-03-01T01:39:14-08:00</updated>
  <author>
    <name>Aaron Fraser</name>
    <uri>http://0.0.0.0:4000</uri>
    <email>me@afraser.io</email>
  </author>
  <content type="html">

  &lt;p&gt;&lt;a href=&quot;http://0.0.0.0:4000/storage-for-vmware/&quot;&gt;Storage For Vmware&lt;/a&gt; was originally published by Aaron Fraser at &lt;a href=&quot;http://0.0.0.0:4000&quot;&gt;Aaron Fraser&lt;/a&gt; on March 01, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Elastic Dns]]></title>
  <link rel="alternate" type="text/html" href="http://0.0.0.0:4000/elastic-dns/" />
  <id>http://0.0.0.0:4000/elastic-dns</id>
  <published>2014-03-01T01:38:47-08:00</published>
  <updated>2014-03-01T01:38:47-08:00</updated>
  <author>
    <name>Aaron Fraser</name>
    <uri>http://0.0.0.0:4000</uri>
    <email>me@afraser.io</email>
  </author>
  <content type="html">

  &lt;p&gt;&lt;a href=&quot;http://0.0.0.0:4000/elastic-dns/&quot;&gt;Elastic Dns&lt;/a&gt; was originally published by Aaron Fraser at &lt;a href=&quot;http://0.0.0.0:4000&quot;&gt;Aaron Fraser&lt;/a&gt; on March 01, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Why Razor?]]></title>
  <link rel="alternate" type="text/html" href="http://0.0.0.0:4000/posts/why-razor/" />
  <id>http://0.0.0.0:4000/posts/why-razor</id>
  <updated>2014-02-28T00:00:00-00:00</updated>
  <published>2014-02-28T00:00:00-08:00</published>
  
  <author>
    <name>Aaron Fraser</name>
    <uri>http://0.0.0.0:4000</uri>
    <email>me@afraser.io</email>
  </author>
  <content type="html">&lt;p&gt;Working at an employer with diverse technological needs requires that what ever tools we use be incrediably versatile and secure. Recent development in &lt;a href=&quot;https://github.com/puppetlabs/razor-server&quot;&gt;Puppetlabs Razor&lt;/a&gt; has made it a viable option. &lt;/p&gt;

&lt;h2 id=&quot;what-is-the-point&quot;&gt;What is the point?&lt;/h2&gt;
&lt;p&gt;If anyone has spent any time in the datacenter managing hardware is a tricky task. Traditional provisioning is based on an unattended scripting framework that relies on core infrastructure technologies like tftp, pxelinux, dhcp, etc… Basically its about getting an OS on hardware, at thats more difficult that it sounds. &lt;/p&gt;

&lt;p&gt;How does one go about provisioning an OS? First a server would need to get an IP address most likely through DHCP. Within DHCP is the “next-server” and “file” options, this enables DHCP-clients to boot into an ROM image to then take further steps. Next steps are either &lt;a href=&quot;http://www.syslinux.org/wiki/index.php/PXELINUX&quot;&gt;PXELINUX&lt;/a&gt; or &lt;a href=&quot;http://ipxe.org/&quot;&gt;iPXE&lt;/a&gt; instructions. Both of these will trigger into network boot of an OS on first boot. &lt;/p&gt;

&lt;h2 id=&quot;history-lesson&quot;&gt;History Lesson&lt;/h2&gt;
&lt;p&gt;When I first started out as a sysadm I was working for a “cloud” storage company before cloud was a thing. This meant LOTS of storage on physical servers. We managed many cabinets of servers and expanded our footprint quite fast. Since our systems were RedHat based, we relied mostly on traditional kickstarting frameworks using DHCP, TFTP, PXELINUX, Kickstart (anaconda) and a MESS of bash. This worked well for us at the time. Configuration was simply configuring DHCPD with the MAC address for each server to an Kick IP, PXELINUX config associating the HEX of the Kick IP to pxelinux.cfg for the OS and a config file associating an Kick IP address to a hostname and Dest IP.
&lt;br /&gt;
&lt;br /&gt;
As nice as this was it was a difficult task to configure more than 10 servers at a time. You had to collect the MACs either with iDRAC/iLO or shipping labels. The configuring of DHCPD is a manual process(retrieving Kick IP, config entry, etc..) as were ther PXELINUX and config file changes. Automation was attempted but nothing as very clean and grabbing MACs slowed the whole process WAY down. This is what I consider an Instruction-based provisioning tool. The tool itself doesnt have a way to identify hardware and make a decision and the configuration isnt separated from the hardware. When you get to an organization where you need to provision hundreds of systems, Instruction-based tools begin to lose there benefits. 
&lt;br /&gt;
&lt;br /&gt;
What if there was a better way?&lt;br /&gt;&lt;/p&gt;

&lt;h4 id=&quot;below-is-a-list-of-common-tools&quot;&gt;Below is a list of common tools:&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/puppetlabs/razor-server&quot;&gt;Razor&lt;/a&gt; - Extensible ruby-based provisioning tool&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://maas.ubuntu.com/&quot;&gt;MaaS&lt;/a&gt; - Ubuntu BareMetal provisioning&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://crowbar.github.io/home.html&quot;&gt;Crowbar&lt;/a&gt; - Cluster provisioning&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.stackiq.com/&quot;&gt;StackIQ&lt;/a&gt; - Cluster-based Provisioning&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cobblerd.org/&quot;&gt;Cobbler&lt;/a&gt; - Kickstart application&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.rocksclusters.org/wordpress/&quot;&gt;Rocks&lt;/a&gt; - HPC Appliance provisioning&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Windows_Deployment_Services&quot;&gt;WDS&lt;/a&gt; - Windows Distribution Services&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.fogproject.org/?q=node/1&quot;&gt;Fog Project&lt;/a&gt; - Free Provisioning &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://theforeman.org/&quot;&gt;theForeman&lt;/a&gt; - BareMetal/Virtual Lifecycle for puppet&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Where I work, we have hundreds of systems. I mean LOTS, like 10x what I had at the storage company. As of this week we have ~100 systems that need an OS. I was able to provision them with nothing more than turning them on and associating the Serial number with a name and IP. About 20 minutes later 80 servers have an OS and are ready for use. This is the benefit of a Discovery-Based provisioning system. 
&lt;br /&gt;
&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;basic-concept&quot;&gt;Basic concept:&lt;/h2&gt;

&lt;p&gt;Below is the explanation of a Discovery-based Provisioning workflow:
&lt;img src=&quot;http://0.0.0.0:4000/images/BMaaS-workflow.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;discovery&quot;&gt;Discovery&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Provisioning Server is built and all services turned on.&lt;/li&gt;
  &lt;li&gt;New hardware is racked and powered on. &lt;/li&gt;
  &lt;li&gt;Hardware PXE boots using DHCP, TFTP and iPXE. &lt;/li&gt;
  &lt;li&gt;iPXE chainloads and checks into Provisioning Server.&lt;/li&gt;
  &lt;li&gt;iPXE lastly loads in-memory OS onto hardware. &lt;/li&gt;
  &lt;li&gt;In-memory OS collects facts about hardware and posts to Provisioning server. &lt;/li&gt;
  &lt;li&gt;Waits for next steps.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;config&quot;&gt;Config&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Collect available hardware nodes from provisioning server.&lt;/li&gt;
  &lt;li&gt;Associates OS and node information to hardware from the available nodes.&lt;/li&gt;
  &lt;li&gt;Post config to Provisioning server.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;provisiong&quot;&gt;Provisiong&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Config is posted to Provisioning server, altering the “next steps” for each node.&lt;/li&gt;
  &lt;li&gt;Nodes check in for next steps and instructions are given to restart.&lt;/li&gt;
  &lt;li&gt;On next PXE boot server chainload iPXE again but instead of the in-memory OS, it loads the install instructions. &lt;/li&gt;
  &lt;li&gt;OS is installed according to configured recipe&lt;/li&gt;
  &lt;li&gt;New OS on hardware registers that it has completed its install to the Provisioning server closing the loop.&lt;/li&gt;
  &lt;li&gt;Broker handoff is initiated. &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;A little bit of scripting at the Config step and you could be capable of building hundreds of servers quickly and precisely. Even better some provisioning tools are designed to provision based on a profile. By this I mean you setup a list of parameters that need to be met for a particular OS to be installed. These profiles are designed to be grow so for each server attempting to install the hostname and IP increment. So say a profile will trigger if the hardware has 4 Hex-Core Processors and 192GB RAM, if matched it will install Hypervisor. For organizations that deal with large clusters of the same hardware, this can be incredibly powerful. Rack and power and in 30 minutes an OS will be installed. &lt;/p&gt;

&lt;h2 id=&quot;what-about-the-app&quot;&gt;What about the app?&lt;/h2&gt;
&lt;p&gt;The app would be the most difficult aspect to install. Countless tools have been built to accomplish this feat and in my mind not a challenge that provisioning needs to tackle. For the customer that are looking to do one thing and one thing well, then a all-in-one provisioner makes immense sense. When your needs range from lots of different hardware, every version of OS one can image and every imaginal application stack makes a all-in-one tool nigh impossible. A good provisioning tool should offer a method to integrate with modern configuration management tools or clustering tools. &lt;/p&gt;

&lt;h2 id=&quot;so-again-why-razor&quot;&gt;So again… why razor?&lt;/h2&gt;
&lt;p&gt;Razor is the only tool that does the following:
1. Declares clearly what it will/willnot control. 
2. Unlike Cobbler and other tools, it doesnt control DHCP config. Completely dependent on DHCP to provide IP to any hardware so that it will load the razor discovery tool. 
2. Abstracts itself to a simple API that does the heavy lifting of OS provisioning called “Tasks”. 
3. Provides connection points between system management toolsets using what they call “Brokers”. 
&lt;br /&gt;
&lt;br /&gt;
With this framework we were able to build a system that can install systems ranging from clusters of Xen Hypervisors to a single Windows 2012 R2 server. That is a powerful tool, especially when the toolset is engineered where it can be managed with modern &lt;a href=&quot;http://en.wikipedia.org/wiki/Continuous_integration&quot;&gt;CI&lt;/a&gt; and &lt;a href=&quot;http://en.wikipedia.org/wiki/Continuous_delivery&quot;&gt;CD&lt;/a&gt; workflows.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://0.0.0.0:4000/posts/why-razor/&quot;&gt;Why Razor?&lt;/a&gt; was originally published by Aaron Fraser at &lt;a href=&quot;http://0.0.0.0:4000&quot;&gt;Aaron Fraser&lt;/a&gt; on February 28, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[SSH and you]]></title>
  <link rel="alternate" type="text/html" href="http://0.0.0.0:4000/posts/ssh-configs/" />
  <id>http://0.0.0.0:4000/posts/ssh-configs</id>
  <updated>2014-02-24T00:00:00-00:00</updated>
  <published>2014-02-24T00:00:00-08:00</published>
  
  <author>
    <name>Aaron Fraser</name>
    <uri>http://0.0.0.0:4000</uri>
    <email>me@afraser.io</email>
  </author>
  <content type="html">&lt;p&gt;Recently been spending alot of time working on side projects for friends and past employers. The number of servers that needs my attention has increased and each of them have separate usernames and ssh keys. To manage this I was using shell aliases &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;alias &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;mysrvr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;ssh -i ~/.ssh/mysrvr.priv root@mysrvr.afraser.io&amp;quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;These worked great and all but I still didnt have an easy way to scp files. Trying to make an alias dynamic enough to be able to scp was a pain (and a useless waste of time..)
Then one day I was exploring this issue and found ssh configs. They proved to be far more powerful. Soon I replaced all my aliases with an ssh_config&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;Host c1-dev
   HostName client1-server01.test.co
   User root
   IdentityFile ~/.ssh/client1.pem
Host c2-dev01
   HostName client2-server01.anothertest.co
   User root
   IdentityFile ~/.ssh/client2.pem
Host mysrvr
   HostName mysrvr.afraser.io
   User root
   IdentityFile ~/.ssh/mysrvr.priv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I have found situations were having an ssh config wasnt going to work out.If you have servers that are only accessible from a very restricted network and dont support ssh keys for what ever reason there is SSHPASS.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
First you’ll need to install it:
&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;sudo apt-get install sshpass
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;To use ssh pass its best to have a sourced file with an environment variable:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;cat bastion-login
  &lt;span class=&quot;nv&quot;&gt;SSH_PASS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&amp;quot;some-horribly-insecure-password&amp;quot;&lt;/span&gt;

&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;source &lt;/span&gt;bastion-login
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Once the file is sourced you can then simply prepend sshpass to your standard ssh commands like so:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;sshpass -e ssh -o &lt;span class=&quot;nv&quot;&gt;StrictHostKeyChecking&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;no  cloud-user@mysrvr.afraser.io 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;In the above example you will see the &lt;code&gt;-o StrictHostKeyChecking=no&lt;/code&gt; this simply auto-accepts/ignores the Host Key check you would normally acknowledge for the first connection to the destination server.&lt;/p&gt;

&lt;p&gt;Those error typically look like this:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;ssh cloud-users@mysrvr.afraser.io
The authenticity of host &lt;span class=&quot;s1&quot;&gt;&amp;#39;mysrvr.afraser.io (208.9.150.2)&amp;#39;&lt;/span&gt; can&lt;span class=&quot;err&quot;&gt;&amp;#39;&lt;/span&gt;t be established.
RSA key fingerprint is cf:1b:f4:1f:c5:aa:b1:1e:bf:4e:5e:cf:53:fa:a8:73.
Are you sure you want to &lt;span class=&quot;k&quot;&gt;continue &lt;/span&gt;connecting &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;yes/no&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;? 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Hopefully this can help make sshing a more pleasurable experience.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://0.0.0.0:4000/posts/ssh-configs/&quot;&gt;SSH and you&lt;/a&gt; was originally published by Aaron Fraser at &lt;a href=&quot;http://0.0.0.0:4000&quot;&gt;Aaron Fraser&lt;/a&gt; on February 24, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Razor and Windows]]></title>
  <link rel="alternate" type="text/html" href="http://0.0.0.0:4000/posts/razor-windows/" />
  <id>http://0.0.0.0:4000/posts/razor-windows</id>
  <updated>2013-05-31T00:00:00-00:00</updated>
  <published>2014-01-04T00:00:00-08:00</published>
  
  <author>
    <name>Aaron Fraser</name>
    <uri>http://0.0.0.0:4000</uri>
    <email>me@afraser.io</email>
  </author>
  <content type="html">&lt;section id=&quot;table-of-contents&quot; class=&quot;toc&quot;&gt;
  &lt;header&gt;
    &lt;h3&gt;Contents&lt;/h3&gt;
  &lt;/header&gt;
&lt;div id=&quot;drawer&quot;&gt;
&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#requirements&quot;&gt;Requirements:&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#configure-repo&quot;&gt;Configure repo&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#resolve-dvdlibarchive-bug&quot;&gt;Resolve DVD/libarchive bug&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#build-wim-file&quot;&gt;Build wim file&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#windows-2012-r2-build&quot;&gt;Windows 2012 R2 Build&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#windows-2008-r2-build&quot;&gt;Windows 2008 R2 Build&lt;/a&gt;        &lt;ul&gt;
          &lt;li&gt;&lt;a href=&quot;#build-steps&quot;&gt;Build Steps:&lt;/a&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#configure-recipe&quot;&gt;Configure Recipe&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#windows-2012-r2&quot;&gt;Windows 2012 R2&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#windows-2008-r2&quot;&gt;Windows 2008 R2&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#unattendedxml&quot;&gt;unattended.xml&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#test&quot;&gt;Test&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

  &lt;/div&gt;
&lt;/section&gt;
&lt;!-- /#table-of-contents --&gt;

&lt;p&gt;Working at an employer with diverse technological needs requires that what ever tools we use be incrediably versatile and secure. Recent development in &lt;a href=&quot;https://github.com/puppetlabs/razor-server&quot;&gt;Puppetlabs Razor&lt;/a&gt; has made it a viable option. &lt;/p&gt;

&lt;h3 id=&quot;requirements&quot;&gt;Requirements:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Functional Razor-server install&lt;/li&gt;
  &lt;li&gt;Access to MSDN or other Windows ISO and License Key&lt;/li&gt;
  &lt;li&gt;Virtualization with host-only networking&lt;/li&gt;
  &lt;li&gt;Windows server 2012 R2 VM&lt;/li&gt;
  &lt;li&gt;Windows server 2008 R2 VM&lt;/li&gt;
  &lt;li&gt;Vagrant (optional)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;configure-repo&quot;&gt;Configure repo&lt;/h3&gt;
&lt;p&gt;Lets create a repo for our window server. This will create the razor repo-store directory and copy the contents of that iso into the intended directory. &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;RAZOR_ADMIN=http://localhost
razor create-repo --name=&amp;lt;repo-name&amp;gt; --iso-url=&amp;lt;url to iso&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;resolve-dvdlibarchive-bug&quot;&gt;Resolve DVD/libarchive bug&lt;/h4&gt;
&lt;p&gt;Razor uses libarchive to setup repos from an iso file. Due to the size of windows server ISOs, it can’t open and copy the into the repo. &lt;/p&gt;

&lt;p&gt;To revolve this we have to mount the iso:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;mount -o loop /mnt/cdrom &amp;lt;iso file&amp;gt;
cp /mnt/cdrom/* &amp;lt;razor-repo-store&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;build-wim-file&quot;&gt;Build wim file&lt;/h3&gt;
&lt;p&gt;To start it would be a good idea to read puppetlabs writeup on installing windows: &lt;a href=&quot;https://github.com/puppetlabs/razor-server/wiki/Installing-windows&quot;&gt;windows instructions&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&quot;windows-2012-r2-build&quot;&gt;Windows 2012 R2 Build&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Install &lt;a href=&quot;http://www.microsoft.com/en-us/download/details.aspx?id=39982&quot;&gt;WinPE5&lt;/a&gt; on your windows server. &lt;/li&gt;
  &lt;li&gt;Download the contents of build-winpe from razor-server repo into a build directory on the windows server. &lt;/li&gt;
  &lt;li&gt;Run the build script: &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;powershell -executionpolicy bypass -noninteractive -file build-razor-winpe.ps1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The build script mounts the wim provided with the ADK. We need to copy a file out of there, bootmgr.exe. We’ll cover the why later. While the build process is  executing, open the build directory you made and head into the razor-wim-mount directory. The path in the mount point is &lt;code&gt;Windows\Boot\PXE\bootmgr.exe&lt;/code&gt;. Copy the file out of the mount as it will need to be placed on the razor repo directory. I found this little trick &lt;a href=&quot;http://blog.devicenull.org/2013/11/14/ipxe-wimboot-and-windows-server-2012r2.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Once the build process is completed please copy the wim and the copied bootmgr.exe file to razor. &lt;/p&gt;

&lt;h4 id=&quot;windows-2008-r2-build&quot;&gt;Windows 2008 R2 Build&lt;/h4&gt;
&lt;p&gt;Puppet build scripts are dependent on DISM cmdlets.&lt;/p&gt;

&lt;h5 id=&quot;build-steps&quot;&gt;Build Steps:&lt;/h5&gt;
&lt;ul&gt;
  &lt;li&gt;Install windows updates:
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.microsoft.com/en-us/download/details.aspx?id=30652&quot;&gt;WinPE4&lt;/a&gt; &lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.microsoft.com/en-us/download/details.aspx?id=30653&quot;&gt;Microsoft .NET Framework 4.5&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;http://www.microsoft.com/en-us/download/details.aspx?id=40855&quot;&gt;Windows Management Framework 4.0&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Download the contents of build-winpe from razor-server repo into a build directory on the windows server. &lt;/li&gt;
  &lt;li&gt;As this is not Windows 8/2012, the DISM cmdlets arent automatically imported. To do so modify the build-razor-winpe.ps1 script:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;import-module dism` -&amp;gt; `import-module &amp;quot;C:\Program Files (x86)\Windows Kit\8.0\Assessment and Deployment Kit\Deployment Tools\amd64\DISM&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Run the build script:&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;powershell -executionpolicy bypass -noninteractive -file build-razor-winpe.ps1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Dont worry about the bootmgr.exe this time, the one copied from 2012 will work here as well. Once the build completes, copy the new winpe.wim to your razor repo for windows 2008 R2. &lt;/p&gt;

&lt;h3 id=&quot;configure-recipe&quot;&gt;Configure Recipe&lt;/h3&gt;
&lt;p&gt;I found that the behaviour in of templating in the recipes to not work as directed. So please copy the windows dir and the windows.yaml and make a copy for each new version of the OS. You will them need to adjust the the boot_wim.erb in each of the recipe directories. &lt;/p&gt;

&lt;h4 id=&quot;windows-2012-r2&quot;&gt;Windows 2012 R2&lt;/h4&gt;
&lt;p&gt;Change from BOOTMGR to bootmgr.exe&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;initrd ${base}/bootmgr.exe			bootmgr.exe
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h4 id=&quot;windows-2008-r2&quot;&gt;Windows 2008 R2&lt;/h4&gt;
&lt;p&gt;Remove the additional fonts from the boot_wim.erb&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;initrd ${base}/boot/fonts/segmono_boot.ttf	segmono_boot.ttf
initrd ${base}/boot/fonts/segoe_slboot.ttf	segoe_slboot.ttf
initrd ${base}/boot/fonts/wgl4_boot.ttf		wgl4_boot.ttf
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;unattendedxml&quot;&gt;unattended.xml&lt;/h3&gt;
&lt;p&gt;You should remove the contents of the current unattended.xml files in 8-pro. This file will not work with Windows Server 2008 R2 nor 2012 R2. It would be best to look over Microsofts documentation process on how to construct an unattended.xml. &lt;/p&gt;

&lt;h3 id=&quot;test&quot;&gt;Test&lt;/h3&gt;
&lt;p&gt;Now all you need to do is configure a policy to use the your new repo and kickstart a windows vm. &lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://0.0.0.0:4000/posts/razor-windows/&quot;&gt;Razor and Windows&lt;/a&gt; was originally published by Aaron Fraser at &lt;a href=&quot;http://0.0.0.0:4000&quot;&gt;Aaron Fraser&lt;/a&gt; on January 04, 2014.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Diastatic Malt Powder]]></title>
  <link rel="alternate" type="text/html" href="http://0.0.0.0:4000/posts/diastatic-malt-powder/" />
  <id>http://0.0.0.0:4000/posts/diastatic-malt-powder</id>
  <updated>2013-12-27T00:00:00-00:00</updated>
  <published>2013-12-27T00:00:00-08:00</published>
  
  <author>
    <name>Aaron Fraser</name>
    <uri>http://0.0.0.0:4000</uri>
    <email>me@afraser.io</email>
  </author>
  <content type="html">&lt;p&gt;Evidently it is nigh-impossible to procure diastatic malt powder in the valley… No kitchen supply or grocer carries it. Rob’s Red mill even stopped selling it recently.&lt;/p&gt;

&lt;p&gt;For those looking for it: 
&lt;a href=&quot;http://www.kingarthurflour.com/shop/items/diastatic-malt-powder-16-oz&quot;&gt;King Arthur&lt;/a&gt;
, 
&lt;a href=&quot;http://www.amazon.com/Diastatic-Malt-Powder-1-lb/dp/B0001AVRRE&quot;&gt;Barry Farms&lt;/a&gt;&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;http://0.0.0.0:4000/posts/diastatic-malt-powder/&quot;&gt;Diastatic Malt Powder&lt;/a&gt; was originally published by Aaron Fraser at &lt;a href=&quot;http://0.0.0.0:4000&quot;&gt;Aaron Fraser&lt;/a&gt; on December 27, 2013.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Nagios behind Nginx]]></title>
  <link rel="alternate" type="text/html" href="http://0.0.0.0:4000/posts/nagios-behind-nginx/" />
  <id>http://0.0.0.0:4000/posts/nagios-behind-nginx</id>
  <updated>2013-05-31T00:00:00-00:00</updated>
  <published>2013-10-22T00:00:00-07:00</published>
  
  <author>
    <name>Aaron Fraser</name>
    <uri>http://0.0.0.0:4000</uri>
    <email>me@afraser.io</email>
  </author>
  <content type="html">&lt;p&gt;Recently changed jobs, Diseny Interactive, and their default web server is Nginx. So to better support nginx I decided to migrate all of the services that I play with to work behind it and today was Nagios’s turn. I followed a few other blogs help in getting the configs straighted out but below is another rendition of this exercise.&lt;/p&gt;

&lt;h2 id=&quot;specs&quot;&gt;Specs:&lt;/h2&gt;
&lt;p&gt;System: Amazon AMI &lt;br /&gt;
Server: Nginx 1.0.15 &lt;br /&gt;
Nagios: 3.3.1   &lt;/p&gt;

&lt;h3 id=&quot;install-nagios--plugins&quot;&gt;Install nagios &amp;amp; plugins:&lt;/h3&gt;
&lt;p&gt;First lets install the packages needed:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;yum install nagios nagios-plugins-all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Before we start services we need to head over to change the ownership of a few files. These files are important for nginx to access on startup:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;chown root:nginx /etc/passwd
chown root:nginx /usr/share/nagios/html/config.inc.php
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Also we need to add nginx to nagios group. This is necessary for nginx to be able to access certain files for FastCGI:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;nagios:x:497:nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;We can now go ahead and start services as we wont be changing any of the nagios configs from here on out:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;# service nagios start
Starting nagios: done.

# chkconfig --level 3 nagios on
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;configure-fastcgi-and-php-scriptsservices&quot;&gt;Configure FastCGI and PHP scripts/services&lt;/h3&gt;
&lt;p&gt;To start you have it install epel. Many of the required packages arent provided with Amazons version of epel&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;wget http://mirror.steadfast.net/epel/6/i386/epel-release-6-7.noarch.rpm
rpm -Uvh epel-release-6-7.noarch.rpm

yum install fcgi spawn-fcgi fcgi-devel
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h5 id=&quot;install-fcgiwrap&quot;&gt;Install fcgiwrap&lt;/h5&gt;
&lt;p&gt;We will need to install fcgiwrap. It is a Simple server for running CGI applications over FastCGI (http://nginx.localdomain.pl/wiki/FcgiWrap). Below are the steps to install fcgiwrap:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;cd /tmp
git clone git://github.com/gnosek/fcgiwrap.git
cd fcgiwrap/
autoreconf -i
make
make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h5 id=&quot;configure-spawn-fcgi&quot;&gt;Configure spawn-fcgi&lt;/h5&gt;
&lt;p&gt;Once fcgiwrap is installed, what we want to do is enable FastCGI and enable us to pass requests.
To begin lets set up spawn-fcgi config located, /etc/sysconfig/spawn-fcgi:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;OPTIONS=&amp;quot;-u nginx -g nginx -a 127.0.0.1 -p 9001 -f /usr/local/sbin/fcgiwrap -P /var/run/spawn-fcgi.pid&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h5 id=&quot;configure-spawn-fcgi-php&quot;&gt;Configure spawn-fcgi-php&lt;/h5&gt;
&lt;p&gt;Next lets set up spawn-fcgi-php config located, /etc/sysconfig/spawn-fcgi-php:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;cp /etc/sysconfig/spawn-fcgi /etc/sysconfig/spawn-fcgi-php
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Add the following line to the newly created file:&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;OPTIONS=&amp;quot;-u nginx -g nginx -a 127.0.0.1 -p 9002 -f /usr/bin/php-cgi -P /var/run/spawn-fcgi-php.pid&amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;h3 id=&quot;install--configure-nginx&quot;&gt;Install &amp;amp; Configure nginx&lt;/h3&gt;
&lt;p&gt;First we will need to install nginx.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;yum install nginx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next lets configure the VirtualHost&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;text&quot;&gt;server {
    server_name  &amp;lt;servername&amp;gt;;

    location / {
        auth_basic &amp;quot;Access to the web interface is restricted&amp;quot;;
        auth_basic_user_file /etc/nagios/passwd;
	index index.php;
        rewrite ^/nagios/(.*) /$1 break;

        root /usr/share/nagios/html;
        fastcgi_index  index.php;
        include /etc/nginx/fastcgi_params;
	fastcgi_param SCRIPT_FILENAME /usr/share/nagios/html$fastcgi_script_name;
        if ($uri ~ &amp;quot;\.php&amp;quot;){
	   fastcgi_pass   127.0.0.1:9002;
        }
    }

    location ~ ^/nagios/cgi-bin/ {
	root /usr/lib64/;        
	include /etc/nginx/fastcgi_params;
        auth_basic &amp;quot;Restricted&amp;quot;;
        auth_basic_user_file /etc/nagios/passwd;
        fastcgi_param  AUTH_USER $remote_user;
        fastcgi_param  REMOTE_USER $remote_user;
	fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
        if ($uri ~ &amp;quot;\.cgi$&amp;quot;){
            fastcgi_pass   127.0.0.1:9001;
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


  &lt;p&gt;&lt;a href=&quot;http://0.0.0.0:4000/posts/nagios-behind-nginx/&quot;&gt;Nagios behind Nginx&lt;/a&gt; was originally published by Aaron Fraser at &lt;a href=&quot;http://0.0.0.0:4000&quot;&gt;Aaron Fraser&lt;/a&gt; on October 22, 2013.&lt;/p&gt;</content>
</entry>

</feed>
